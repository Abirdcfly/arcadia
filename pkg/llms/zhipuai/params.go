/*
Copyright 2023 KubeAGI.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

	http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// NOTE: Reference zhipuai's python sdk: model_api/params.py and https://open.bigmodel.cn/dev/api#glm-4

package zhipuai

import (
	"encoding/json"
	"errors"

	"github.com/kubeagi/arcadia/pkg/llms"
)

type Role string

const (
	System    Role = "system"
	User      Role = "user"
	Assistant Role = "assistant"
	Tool      Role = "tool"
)

var _ llms.ModelParams = (*ModelParams)(nil)

// +kubebuilder:object:generate=true
// ZhiPuAIParams defines the params of ZhiPuAI Prompt Call
type ModelParams struct {
	// The model to be called
	Model string `json:"model"`
	// Contents
	Messages []Message `json:"messages"`
	// Passed by the client, need to ensure the uniqueness;
	// it isused to distinguish between the unique identity of each request,
	// the platform will be generated by default when the client does not pass.
	RequestID string `json:"request_id,omitempty"`
	// Sampling strategy is enabled when do_sample is true,
	// and sampling strategies temperature and top_p are not effective when do_sample is false. TODO
	DoSample bool `json:"do_sample,omitempty"`
	// Stream seting to true means use sse
	Stream bool `json:"stream,omitempty"`
	// Temperature is float in zhipuai (0.0,1.0], default is 0.95
	Temperature float32 `json:"temperature,omitempty"`
	// TopP is float in zhipuai, (0.0, 1.0) default is 0.7
	TopP      float32 `json:"top_p,omitempty"`
	MaxTokens int     `json:"max_tokens,omitempty"`
	// The model will stop generating when it encounters a character formulated by stop,
	// currently only a single stop word is supported, in the format of ["stop_word1"].
	Stop []string `json:"stop,omitempty"`
	// The list of tools available to LLM, the tools field counts the tokens and
	// is also limited by the length of the tokens.
	Tools []ToolReq `json:"tools,omitempty"`
	// only auto now
	ToolChoice string `json:"tool_choice,omitempty"`
}

type ToolReq struct {
	// function、retrieval、web_search
	Type      string    `json:"type"`
	Function  Function  `json:"function,omitempty"`
	Retrieval Retrieval `json:"retrieval,omitempty"`
	WebSearch WebSearch `json:"web_search,omitempty"`
}

type Function struct {
	// Can only contain a-z, A-Z, 0-9, underscores and centered lines. Maximum length limit is 64
	Name        string `json:"name"`
	Description string `json:"description"`
	Parameters  any    `json:"parameters,omitempty"`
}

type Retrieval struct {
	KnowledgeID    string `json:"knowledge_id"`
	PromptTemplate string `json:"prompt_template,omitempty"`
}

type WebSearch struct {
	Enable      bool   `json:"enable,omitempty"`
	SearchQuery string `json:"search_query,omitempty"`
}

// +kubebuilder:object:generate=true
// Message defines the content of ZhiPuAI Prompt Call
type Message struct {
	Role    Role   `json:"role,omitempty"`
	Content string `json:"content,omitempty"`
	// content and tool_calls must choose one
	ToolCalls []ToolCall `json:"tool_calls,omitempty"`
	// only used when role is `tool`
	ToolCallID string `json:"tool_call_id,omitempty"`
}

type ToolCall struct {
	ID string `json:"id"`
	// web_search、retrieval、function
	Type     string           `json:"type"`
	Function FunctionToolCall `json:"function"`
}

type FunctionToolCall struct {
	Name       string `json:"name"`
	Parameters any    `json:"parameters"`
}

func DefaultModelParams() ModelParams {
	return ModelParams{
		Model:       llms.ZhiPuAILite,
		Temperature: 0.8, // more accurate?
		TopP:        0.7,
		Messages:    make([]Message, 0),
	}
}

func (params *ModelParams) Marshal() []byte {
	data, err := json.Marshal(params)
	if err != nil {
		return []byte{}
	}
	return data
}

func (params *ModelParams) Unmarshal(bytes []byte) error {
	return json.Unmarshal(bytes, params)
}

// MergeZhiPuAI merges b to a  with this rule
// - if a.x is empty and b.x is not, then a.x = b.x
func MergeParams(a, b ModelParams) ModelParams {
	if a.Model == "" && b.Model != "" {
		a.Model = b.Model
	}
	if a.Temperature == 0 && b.Temperature != 0 {
		a.Temperature = b.Temperature
	}
	if a.TopP == 0 && b.TopP != 0 {
		a.TopP = b.TopP
	}
	if !a.Stream && b.Stream {
		a.Stream = b.Stream
	}
	if len(a.Messages) == 0 && len(b.Messages) > 0 {
		a.Messages = b.Messages
	}
	return a
}

func ValidateModelParams(params ModelParams) error {
	if params.Model == "" {
		return errors.New("model is required")
	}

	if params.Temperature < 0 || params.Temperature > 1 {
		return errors.New("temperature must be in [0, 1]")
	}

	if params.TopP < 0 || params.TopP > 1 {
		return errors.New("top_p must be in [0, 1]")
	}

	switch params.Method {
	case ZhiPuAIInvoke, ZhiPuAIAsyncInvoke, ZhiPuAISSEInvoke:
	case ZhiPuAIAsyncGet:
		if params.TaskID == "" {
			return errors.New("task_id is required")
		}
	default:
		return errors.New("method must be one of [invoke, async-invoke, sse-invoke,get]")
	}

	return nil
}
